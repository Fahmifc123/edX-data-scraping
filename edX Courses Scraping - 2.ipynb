{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>edX Courses Scraping - Notebook 2</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only around 1000 courses are found on the course page of the edX website. To scrap all courses, we should follow an alternative approach. Hence, I'm going to scrap courses subject wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scarping the subject page - [edX]('https://www.edx.org/subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "#opening edx subject url\n",
    "driver.get('https://www.edx.org/subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 subjects found\n"
     ]
    }
   ],
   "source": [
    "#extracting the links of the individual subject pages\n",
    "all_sub = driver.find_elements_by_xpath('(//div[@class=\"col-12 mb-4\"])[last()]//li[@class=\"subject-card mb-3\"]/a')\n",
    "all_sub_links = {}\n",
    "for sub in all_sub:\n",
    "    subject = sub.text\n",
    "    links = sub.get_attribute('href')\n",
    "    all_sub_links[subject] = links\n",
    "#close the driver   \n",
    "driver.close() \n",
    "#print number of courses available\n",
    "print(f'There are {len(all_sub)} subjects found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are two types of subject pages available in edx page\n",
    "#writing a function to call respective page for each page type\n",
    "def load_and_fetch_courses(link):\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(link)\n",
    "    \n",
    "    course_found = len(driver.find_elements_by_xpath('//div[@class=\"lazyload-wrapper\"]'))\n",
    "    driver.close()\n",
    "    if course_found :\n",
    "        return fetch_courses_1(link,course_found)\n",
    "    else:\n",
    "        return fetch_courses_2(link)\n",
    "\n",
    "#writing a function to extract courses links from type 1 page    \n",
    "def fetch_courses_1(link,course_found):\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(link)\n",
    "    \n",
    "    time_scroll = course_found//10\n",
    "    #scroll down untill all courses get loaded\n",
    "    scroll = 500\n",
    "    for _ in range(time_scroll):\n",
    "        time.sleep(20)\n",
    "        scroll += 500\n",
    "        if _ == (time_scroll - 1):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        else:\n",
    "            driver.execute_script(\"window.scrollTo(0,\" + str(scroll) + \");\")\n",
    "            \n",
    "    #wait another 20 seconds for the last courses to get loaded\n",
    "    time.sleep(20)   \n",
    "    #get a list of all courses available in the current page\n",
    "    courses_driver = driver.find_elements_by_xpath('(//div[@class=\"row card-columns mt-4 pt-4 discovery-card-list\"])[last()]//div/a')\n",
    "    #extract the links of the courses\n",
    "    course_links = []\n",
    "    for courses in courses_driver:\n",
    "        course_links.append(courses.get_attribute('href'))\n",
    "    \n",
    "    #close the driver   \n",
    "    driver.close()\n",
    "    #return the course links\n",
    "    return course_links\n",
    "\n",
    "#writing a function to extract courses links from type 2 page  \n",
    "def fetch_courses_2(link):\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(link)\n",
    "    \n",
    "    #finding the main course link and loading that\n",
    "    main_link = driver.find_element_by_xpath('//a[@class=\"link d-sm-flex d-block\"]').get_attribute('href')\n",
    "    driver.get(main_link)\n",
    "    time.sleep(20)\n",
    "    #clicking the course tab of the loaded page\n",
    "    driver.find_element_by_xpath('(//button[@class=\"show-all-link btn btn-link link d-inline-block px-0\"])[last()]').click()\n",
    "    time.sleep(20)\n",
    "    #calculating number of pages \n",
    "    page_str = driver.find_element_by_xpath('(//button[@class=\"btn page-link\"])[last()]').text\n",
    "    total_page = int(page_str)\n",
    "    \n",
    "    course_links = []\n",
    "    page = 1\n",
    "    #looping through the pages to get course links\n",
    "    while page <= total_page:  \n",
    "        #Xpath of the courses\n",
    "        c_xpath = '//div[@class=\"discovery-card Verified and Audit col col-xl-3 mb-4 scrollable-discovery-card-spacing\"]/a[@class=\"discovery-card-link\"]'\n",
    "        #get a list of all courses available in the current page\n",
    "        courses = driver.find_elements_by_xpath(c_xpath)\n",
    "        #extract the links of the courses\n",
    "        for course in courses:\n",
    "            course_links.append(course.get_attribute('href'))\n",
    "        #Check whether current page is last page or not\n",
    "        if page != total_page:\n",
    "            #click the next page button\n",
    "            driver.find_element_by_xpath('//button[@class=\"btn next page-link\"]').click()\n",
    "            page += 1\n",
    "            #wait until program moves to next page\n",
    "            check = '//button[@aria-label=\"Page ' + str(page) + ', Current Page\"]'\n",
    "            WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, c_xpath)))\n",
    "            #wait for another 30 seconds for the page to load completely\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #close the driver\n",
    "    driver.close()\n",
    "    #return the course links\n",
    "    return course_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the course link for each subject and adding it to the dictonary\n",
    "for sub in all_sub_links:\n",
    "    each_sub_courses = load_and_fetch_courses(all_sub_links[sub])\n",
    "    all_sub_links[sub] = [all_sub_links[sub],each_sub_courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2831 courses across all subjects in edX\n"
     ]
    }
   ],
   "source": [
    "#calculating total number of course links extracted\n",
    "all_courses = []\n",
    "for sub in all_sub_links:\n",
    "    all_courses.extend(all_sub_links[sub][1])\n",
    "#set stores only unique values\n",
    "all_courses = set(all_courses)\n",
    "print(f'There are {len(all_courses)} courses across all subjects in edX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since Philanthropy subject has different format, for loop got broke. Lets seperate it and extract other subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missed subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed subjects are ['Philosophy & Ethics', 'Physics', 'Science', 'Social Sciences']\n"
     ]
    }
   ],
   "source": [
    "missed_subjects = []\n",
    "#extract the subjects that didn't get loaded\n",
    "for sub in all_sub_links:\n",
    "    if len(all_sub_links[sub]) !=2 :\n",
    "        missed_subjects.append(sub) \n",
    "#removing Philanthropy        \n",
    "missed_subjects.remove('Philanthropy')\n",
    "print(f'Missed subjects are {missed_subjects}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the course link for missed subjects and adding it to the dictonary\n",
    "for sub in missed_subjects:\n",
    "    each_sub_courses = load_and_fetch_courses(all_sub_links[sub])\n",
    "    all_sub_links[sub] = [all_sub_links[sub],each_sub_courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the course link of Philanthropy \n",
    "sub_courses = fetch_courses_1(all_sub_links['Philanthropy'],0)\n",
    "all_sub_links['Philanthropy'] = [all_sub_links['Philanthropy'],sub_courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2987 courses across all subjects in edX\n"
     ]
    }
   ],
   "source": [
    "#calculating total number of course links extracted\n",
    "all_courses = []\n",
    "for sub in all_sub_links:\n",
    "    all_courses.extend(all_sub_links[sub][1])\n",
    "#set stores only unique values\n",
    "all_courses = set(all_courses)\n",
    "print(f'There are {len(all_courses)} courses across all subjects in edX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the extracted links as pickle, so that it can be used in next notebooks for further analysis\n",
    "with open('Data/all_sub_links.pkl','wb') as file:\n",
    "    pickle.dump(all_sub_links,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
