{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>edX Courses Scraping - Notebook 3</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be scraping data from individual course links extracted from each subject page of edX website in previous notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating not extracted course links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have extracted 2987 course links in previous notebook, in which I have already scraped 998 course links in first notebook. Hence, I'm seperating course links those are not yet scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unloading the pickled dictionary \n",
    "with open('Data/all_sub_links.pkl','rb') as file:\n",
    "    all_sub_links = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the unique course links \n",
    "all_courses = []\n",
    "for sub in all_sub_links:\n",
    "    all_courses.extend(all_sub_links[sub][1])\n",
    "#set stores only unique values\n",
    "all_courses = set(all_courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the courses already scraped \n",
    "course_details = pd.read_csv('Data/edX_Course.csv')\n",
    "extracted_courses = set(course_details['Course Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1989 courses yet to be scraped\n"
     ]
    }
   ],
   "source": [
    "#finding the courses not scraped\n",
    "not_extracted_courses = all_courses.difference(extracted_courses)\n",
    "print(f'There are {len(not_extracted_courses)} courses yet to be scraped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the individual course pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing functions to extract and return required value from each edX course page\n",
    "#these functions will return 'Missing' if certain fields are not found in course page\n",
    "\n",
    "def get_title():\n",
    "    try:\n",
    "        title = driver.find_element_by_xpath('//h1[@class=\"course-intro-heading mb-2\"]').text\n",
    "    except:\n",
    "        title = 'Missing'\n",
    "    finally:\n",
    "        return title\n",
    "    \n",
    "def get_short_description():\n",
    "    try:\n",
    "        des = driver.find_element_by_xpath('//div[@class=\"course-intro-lead-in mb-3\"]/p').text\n",
    "    except:\n",
    "        des = 'Missing'\n",
    "    finally:\n",
    "        return des\n",
    "    \n",
    "def get_length():\n",
    "    try:\n",
    "        length = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[1]')\n",
    "        length = length.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        length = 'Missing'\n",
    "    finally:\n",
    "        return length\n",
    "    \n",
    "def get_effort():\n",
    "    try:\n",
    "        effort = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[2]')\n",
    "        effort = effort.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        effort = 'Missing'\n",
    "    finally:\n",
    "        return effort\n",
    "\n",
    "def get_price():\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[3]')\n",
    "        price = price.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "        #extract only the value starting with $ or ₹\n",
    "        price = re.findall(r'[\\$\\₹].*', price)[0]\n",
    "    except:\n",
    "        price = 'Missing'\n",
    "    finally:\n",
    "        return price\n",
    "\n",
    "def get_institution():\n",
    "    try:\n",
    "        institution = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[4]')\n",
    "        institution = institution.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        institution = 'Missing'\n",
    "    finally:\n",
    "        return institution\n",
    "\n",
    "def get_subject():\n",
    "    try:\n",
    "        subject = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[5]')\n",
    "        subject = subject.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        subject = 'Missing'\n",
    "    finally:\n",
    "        return subject\n",
    "\n",
    "def get_level():\n",
    "    try:\n",
    "        level = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[6]')\n",
    "        level = level.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        level = 'Missing'\n",
    "    finally:\n",
    "        return level\n",
    "    \n",
    "def get_language():\n",
    "    try:\n",
    "        language = driver.find_element_by_xpath('(//li[@class=\"list-group-item d-flex row px-0\"])[7]')\n",
    "        language = language.find_element_by_xpath('./div[@class=\"col\"]').text\n",
    "    except:\n",
    "        language = 'Missing'\n",
    "    finally:\n",
    "        return language\n",
    "\n",
    "def get_prerequisites():\n",
    "    try:\n",
    "        prerequisites = driver.find_element_by_xpath('//div[@class=\"col prerequisite-sidebar\"]//p').text\n",
    "    except:\n",
    "        prerequisites = 'Missing'\n",
    "    finally:\n",
    "        return prerequisites\n",
    "    \n",
    "def get_img_src():\n",
    "    try:\n",
    "        image = driver.find_element_by_xpath('//img[@class=\"header-image\"]').get_attribute('src')\n",
    "    except:\n",
    "        try:\n",
    "            image = driver.find_element_by_xpath('//img[@class=\"video-thumb\"]').get_attribute('src') \n",
    "        except:\n",
    "            image = \"Missing\"\n",
    "    finally:\n",
    "        return image\n",
    "        \n",
    "def get_already_enrolled():\n",
    "    try:\n",
    "        enrolled = driver.find_element_by_xpath('//div[@id=\"js-number-enrolled-label\"]/span/span').text\n",
    "        enrolled = int(enrolled.replace(',',''))\n",
    "    except:\n",
    "        enrolled = 'Missing'\n",
    "    finally:\n",
    "        return enrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through course link and fetch required fields\n",
    "for course_link in not_extracted_courses:\n",
    "    course_dict = {}\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(course_link)\n",
    "    \n",
    "    #extract information using functions and storing it in temp dict    \n",
    "    course_dict['Course Link'] = course_link\n",
    "    course_dict['Title'] = get_title()\n",
    "    course_dict['Short Description'] = get_short_description()\n",
    "    course_dict['Length'] = get_length()\n",
    "    course_dict['Effort'] = get_effort()\n",
    "    course_dict['Price'] = get_price()\n",
    "    course_dict['Institution'] = get_institution()\n",
    "    course_dict['Subject'] = get_subject()\n",
    "    course_dict['Level'] = get_level()\n",
    "    course_dict['Prerequisites'] = get_prerequisites()\n",
    "    course_dict['Image Source'] = get_img_src()\n",
    "    course_dict['Already Enrolled'] = get_already_enrolled()\n",
    "    course_dict['Language'] = get_language()\n",
    "    driver.close()\n",
    "    \n",
    "    #append the extracted info to the DataFrame\n",
    "    course_details = course_details.append(course_dict,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missed links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In addition to the courses, some subjects will have other certification programs like xseries,micro masters,professional certification. It should extracted in different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing xseries,micro masters,professional certification courses\n",
    "course_details = course_details[course_details['Course Link'].str.contains('course')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 courses are missed\n"
     ]
    }
   ],
   "source": [
    "#seperating missed links\n",
    "missed_links = list(course_details[course_details['Title'] == 'Missing']['Course Link'])\n",
    "\n",
    "if len(missed_links):\n",
    "    print(f'{len(missed_links)} courses are missed')\n",
    "else:\n",
    "    print(\"All courses got loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the missed courses from DataFrame\n",
    "course_details = course_details[course_details.Title != 'Missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through missed course link and fetch required fields\n",
    "for course_link in missed_links:\n",
    "    course_dict = {}\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(course_link)\n",
    "    \n",
    "    #extract information using functions and storing it in temp dict    \n",
    "    course_dict['Course Link'] = course_link\n",
    "    course_dict['Title'] = get_title()\n",
    "    course_dict['Short Description'] = get_short_description()\n",
    "    course_dict['Length'] = get_length()\n",
    "    course_dict['Effort'] = get_effort()\n",
    "    course_dict['Price'] = get_price()\n",
    "    course_dict['Institution'] = get_institution()\n",
    "    course_dict['Subject'] = get_subject()\n",
    "    course_dict['Level'] = get_level()\n",
    "    course_dict['Prerequisites'] = get_prerequisites()\n",
    "    course_dict['Already Enrolled'] = get_already_enrolled()\n",
    "    course_dict['Language'] = get_language()\n",
    "    driver.close()\n",
    "    \n",
    "    #append the extracted info to the DataFrame\n",
    "    course_details = course_details.append(course_dict,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missed links\n",
    "(course_details['Title'] == 'Missing').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Still some courses are missing. Lets examine their links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed courses are ['https://www.edx.org/professional-certificate/edx-course-creator-plus']\n"
     ]
    }
   ],
   "source": [
    "#seperating missed links\n",
    "missed_links = list(course_details[course_details['Title'] == 'Missing']['Course Link'])\n",
    "\n",
    "print(f'Missed courses are {missed_links}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Course missed is a professional certificate, which will be extracted in next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_details['Effort'] = course_details['Effort'].str.replace('–','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the extracted data to CSV file\n",
    "course_details.to_csv('Data/edX_Course.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
